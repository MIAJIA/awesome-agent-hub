{
  "category": "experimental",
  "status": "alpha",
  "purpose": "",
  "principle": "",
  "reusability": "",
  "limitations": "",
  "demo_links": [],
  "platforms": [],
  "stack": [
    "TypeScript",
    "Python",
    "Jupyter Notebook",
    "Go",
    "Rust",
    "HTML",
    "JavaScript",
    "MDX",
    "Kotlin",
    "Ruby",
    "C",
    "Shell",
    "Handlebars",
    "Java",
    "C#",
    "C++",
    "Julia",
    "PHP",
    "Bicep",
    "Scala",
    "Dart",
    "Svelte",
    "PowerShell",
    "GDScript",
    "Elixir",
    "Ballerina",
    "Vue",
    "SCSS",
    "Move",
    "Typst",
    "Clojure",
    "Lua",
    "YARA",
    "Fluent",
    "Zig"
  ],
  "name": "LlamaIndexTS",
  "slug": "run-llama-llamaindexts",
  "description": "Data framework for your LLM applications. Focus on server side solution",
  "repository": "https://github.com/run-llama/LlamaIndexTS",
  "stars": 2647,
  "originator": "run-llama",
  "tags": [
    "agent",
    "chatbot",
    "claude-ai",
    "create-llama",
    "embedding",
    "groq-ai",
    "javascript",
    "llama",
    "llama-index",
    "llama3",
    "llamaindex",
    "llm",
    "node",
    "nodejs",
    "openai",
    "react",
    "typescript"
  ],
  "open_source": true,
  "license": "MIT",
  "last_updated": "2025-05-28",
  "language": "TypeScript"
}