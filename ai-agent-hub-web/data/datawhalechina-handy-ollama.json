{
  "category": "education",
  "status": "alpha",
  "purpose": "To educate users on deploying and running large language models using CPUs, specifically focusing on the Ollama framework.",
  "principle": "Leverages tutorials and examples to guide users through the process of setting up and deploying models using Ollama on CPU-based systems.",
  "reusability": "The tutorial can be used as a learning resource for understanding CPU-based deployment of large language models, and the examples can be adapted for similar use cases.",
  "limitations": "Primarily designed for educational purposes, may not cover all edge cases or advanced deployment scenarios.",
  "platforms": [
    "Linux",
    "MacOS"
  ],
  "stack": [
    "Jupyter Notebook",
    "LangChain",
    "LlamaIndex",
    "Python"
  ],
  "name": "handy-ollama",
  "slug": "datawhalechina-handy-ollama",
  "description": "动手学Ollama，CPU玩转大模型部署，在线阅读地址：https://datawhalechina.github.io/handy-ollama/",
  "repository": "https://github.com/datawhalechina/handy-ollama",
  "stars": 1675,
  "originator": "datawhalechina",
  "tags": [
    "agent",
    "gguf",
    "langchain",
    "large-language-models",
    "llamaindex",
    "llm",
    "ollama",
    "rag",
    "tutorial"
  ],
  "open_source": true,
  "license": "NOASSERTION",
  "last_updated": "2025-03-04",
  "language": "Jupyter Notebook",
  "useful_links": [
    "https://datawhalechina.github.io/handy-ollama/"
  ],
  "highlight": "A comprehensive tutorial for deploying large language models on CPU using Ollama."
}